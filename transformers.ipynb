{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a2edd9-c21a-4107-81ab-e034755e7541",
   "metadata": {},
   "source": [
    "# Preprocessing with a tokenizer\n",
    "\n",
    "Comenzamos importando AutoTokenizer de la biblioteca transformers de Hugging Face. El tokenizador se utiliza para convertir texto en un formato que el modelo puede entender, esencial para tareas de procesamiento de lenguaje natural.\n",
    "Utilizamos el modelo distilbert-base-uncased-finetuned-sst-2-english, que es una versión destilada y afinada del BERT, optimizada para la tarea de análisis de sentimientos en textos en inglés. Este modelo proporciona un equilibrio entre precisión y velocidad, siendo adecuado para inferencias en tiempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fe89dc-c61d-4df8-a13d-3b6a3d41d055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067347a593ae4cff8a471ba29a7feffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37c70cee19f4cf9af8dd9c3862e8060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4abac8ab1d14e8dac192a26bcd4f5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6394f20412a44a1bb64b8a4e53d1c791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667d155fdafc4ba0a65b7ae4ecc4952d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, force_download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35ba27-0df9-4c77-9823-f4b30001608a",
   "metadata": {},
   "source": [
    "El proceso de tokenización convierte cada texto en una serie de tokens o identificadores que representan palabras o segmentos de palabras. El modelo utiliza estos tokens para entender y analizar el contenido del texto  \n",
    "Parámetros   \n",
    "**padding**=True: Asegura que todas las secuencias tokenizadas tengan la misma longitud rellenando con tokens especiales donde sea necesario.  \n",
    "**truncation**=True: Recorta las secuencias que excedan la longitud máxima permitida por el modelo.  \n",
    "**return_tensors**=\"pt\": Devuelve los tokens en un tensor de PyTorch, adecuado para el modelo que estamos utilizando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09eaa5e7-4753-40dd-84b3-3f67aef972ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5afb0-0326-4ab4-a3d8-9538eebbaf0e",
   "metadata": {},
   "source": [
    "# Going through the model\n",
    "Después de preparar los textos mediante tokenización, el siguiente paso es cargar el modelo que usaremos para clasificar el sentimiento de los textos. En esta sección, cargaremos un modelo pre-entrenado de Hugging Face Transformers específicamente afinado para la tarea de clasificación de sentimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c1ab848-d42e-46ff-ae8f-ac7c476b5447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45261e05b5648c4b1e27300fdef1dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f25a15277054197bbc271b6d43461d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92509e7ee0a44b439f9e0aeb7078e53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b0db4d9-7f02-42a0-a541-351dffb13a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
      "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e1858-cfe5-4665-95eb-3c5127d51b0e",
   "metadata": {},
   "source": [
    "Una vez que hemos realizado la inferencia utilizando el modelo, es útil entender la estructura de los resultados. En este caso, estamos interesados en los logits, que son las salidas crudas del modelo antes de aplicar una función de activación como la softmax.\n",
    "\n",
    "¿Qué son los Logits?\n",
    "Los logits son las puntuaciones sin procesar que cada clase recibe en un problema de clasificación. En nuestro contexto, estos logits representarán las puntuaciones para las categorías de sentimientos (positivo y negativo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0420b25a-56a2-4226-89d3-06cd28aca8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4ed42-1fa3-4b47-9e01-28c7cabde321",
   "metadata": {},
   "source": [
    "# Postprocessing the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24ca41bd-8aa7-4c0a-abd5-959371d7ad8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5607,  1.6123],\n",
      "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff34a5e-8aa5-4231-82d3-505e840d04ac",
   "metadata": {},
   "source": [
    "Después de obtener los logits del modelo, el siguiente paso es convertir estas puntuaciones brutas en probabilidades utilizando la función softmax. Esto nos ayudará a interpretar más fácilmente los resultados como probabilidades de cada clase.\n",
    "\n",
    "¿Qué hace la función Softmax?\n",
    "La función softmax convierte los logits, que son valores reales arbitrarios, en valores que suman 1, lo que los hace interpretables como probabilidades. Cada valor representa la probabilidad de que la entrada pertenezca a una clase particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c45dcea7-ce51-4333-b075-b201190318d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0195e-02, 9.5980e-01],\n",
      "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6946ae92-8336-4a67-8148-7d351264e4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bff78e-30bf-4a40-9730-eb8807d43c2c",
   "metadata": {},
   "source": [
    "# Using Pipeline\n",
    "Para simplificar el proceso de clasificación de sentimientos, podemos utilizar la función pipeline de la biblioteca Hugging Face Transformers. Esta herramienta nos permite cargar directamente un modelo con sus dependencias asociadas y aplicarlo a los textos de forma inmediata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85b158ec-595a-4a97-a7ce-ca8e70319900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3305d-e2fe-4edc-bb55-7a128d24c20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
